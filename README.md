## üöÄ Proyecto MLOps ‚Äì Canalizaci√≥n de Datos y ML Metadata

¬°Bienvenido al proyecto! Este repositorio demuestra c√≥mo construir un ambiente de desarrollo MLOps usando TFX, Docker y Jupyter Lab. Aqu√≠ se muestran todas las etapas:

Ingesta y selecci√≥n de caracter√≠sticas del dataset Forest Cover Type
Generaci√≥n de estad√≠sticas, inferencia y curado del esquema (con entornos TRAINING y SERVING)
Transformaci√≥n e ingenier√≠a de caracter√≠sticas mediante preprocesamiento personalizado
Registro y consulta de ML Metadata para rastrear la procedencia de los artefactos
üì• Descarga del Repositorio
Para descargar el proyecto desde GitHub, ejecuta el siguiente comando en la terminal:

git clone https://github.com/zafrar0926/Proyecto1.git

Luego, navega al directorio clonado:

cd Proyecto1
üê≥ Entorno de Ejecuci√≥n con Docker
Este proyecto se ejecuta dentro de un contenedor Docker. Aseg√∫rate de tener Docker instalado en tu m√°quina o en la m√°quina virtual.

### 1. Creaci√≥n de la Imagen Docker
El Dockerfile se encuentra en la ra√≠z del proyecto y tiene el siguiente contenido:

dockerfile

FROM python:3.9
RUN mkdir /work
WORKDIR /work
COPY . .
RUN python -m pip install --upgrade pip
RUN pip install -r requirements.txt
RUN pip install apache-beam[interactive]==2.45.0
RUN pip install jupyter==1.0.0 -U && pip install jupyterlab==3.6.1
EXPOSE 8888
ENTRYPOINT ["jupyter", "lab", "--ip=0.0.0.0", "--allow-root"]
Para construir la imagen, ejecuta:

bash
docker build -t imagen_proyecto1 .

###  2. Levantar el Contenedor
Ejecuta el siguiente comando para levantar el contenedor:

bash
docker run -d -p 8888:8888 -v "C:\Users\santi\Downloads\Learning\Maestria\MLOps\Proyecto_1\Desarrollo":/work --name contenedor_proyecto1 imagen_proyecto1
Detalles:

-d: Modo "detached" (segundo plano)
-p 8888:8888: Mapea el puerto 8888 del contenedor al mismo puerto en tu m√°quina
-v "ruta_local":/work: Monta el directorio del proyecto en /work dentro del contenedor
--name contenedor_proyecto1: Asigna un nombre al contenedor
Para acceder a Jupyter Lab, revisa los logs del contenedor para obtener el URL y token. Por ejemplo:

bash
docker logs contenedor_proyecto1
Abre el URL que aparezca (por ejemplo, http://<IP_MV>:8888/?token=...) en tu navegador.

### üìì Ejecuci√≥n del Pipeline (Desarrollo.ipynb)
El notebook Desarrollo.ipynb contiene el pipeline completo, que incluye:

1. Descarga y Preparaci√≥n del Dataset
Descarga de datos:
Se descarga el dataset Forest Cover Type y se guarda en ./data/covertype/original.
Selecci√≥n de caracter√≠sticas:
Se eliminan columnas no deseadas y se realiza una selecci√≥n univariante usando SelectKBest.
El subconjunto resultante se guarda en
/work/notebooks/data/covertype/transformed/covertype_train_numeric_selected.csv.
2. Prueba de Modelo Simple (Opcional)
Se divide el dataset, se estandariza y se entrena un modelo Random Forest para obtener una m√©trica de precisi√≥n.
3. Data Pipeline con TFX
Conexi√≥n a Metadata:
Se configura una base de datos SQLite en /work/notebooks/ml_metadata.sqlite para almacenar artefactos.
Ingesta con ExampleGen:
Se convierte el CSV en TFRecords.
Estad√≠sticas y Esquema:
Se calculan estad√≠sticas con StatisticsGen y se infiere un esquema con SchemaGen.
Luego se "cura" el esquema (ajustando rangos y definiendo entornos TRAINING y SERVING).
Validaci√≥n de Inferencia:
Se simula un dataset de servicio (sin la columna Cover_Type) y se valida con ExampleValidator.
Transformaci√≥n (Ingenier√≠a de Caracter√≠sticas):
Se aplica una funci√≥n de preprocesamiento (definida en modules/preprocessing.py) mediante el componente Transform.
4. Exploraci√≥n y Consulta de ML Metadata
Se registran y consultan artefactos (Examples, ExampleStatistics, Schema, etc.) para rastrear la procedencia y validaci√≥n de los datos.

‚öôÔ∏è Dependencias
El archivo requirements.txt contiene:

tfx==1.12.0
apache-beam==2.45.0
jsonschema==3.2.0
scikit-learn==1.6.1
Aseg√∫rate de que todas las dependencias se instalen correctamente durante la construcci√≥n de la imagen.

üìã Requisitos del Taller
Este proyecto cumple con todos los puntos especificados en el taller:

Ingesta y transformaci√≥n de datos:
Con ExampleGen, StatisticsGen, SchemaGen, y Transform.
Curado y validaci√≥n del esquema:
Se ajustan rangos (ej. Hillshade 9am: 0‚Äì255, Slope: 0‚Äì90) y se definen entornos TRAINING y SERVING.
Ingenier√≠a de caracter√≠sticas:
Se aplica preprocesamiento consistente en entrenamiento e inferencia.
Registro y seguimiento de metadatos:
Se exploran los artefactos y se rastrea la procedencia usando ML Metadata.
Entorno reproducible:
Se utiliza Docker para crear un ambiente aislado y versionado.
Versionamiento:
El c√≥digo est√° versionado en GitHub: [Proyecto1](https://github.com/zafrar0926/Proyecto1)
üìù Notas Adicionales
Configuraci√≥n de Rutas:
Revisa que las rutas dentro de los notebooks y scripts coincidan con la estructura del directorio en la MV.
Acceso a Jupyter Lab:
Consulta los logs del contenedor para obtener el URL y token de acceso.
Actualizaci√≥n del Esquema y ML Metadata:
Se muestran funciones para consultar y rastrear artefactos en la metadata, facilitando la auditor√≠a del pipeline.

üìû Desarrollado por:
Edwin A. Caro
Andres F. Matallana
Santiago Zafra Rodr√≠guez