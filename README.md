## üöÄ Proyecto MLOps ‚Äì Canalizaci√≥n de Datos y ML Metadata
## üöÄ Edwin A. Caro (EDCAJI)
## üöÄAndres F. Matallana (ANDRESMLZ)
## üöÄSantiago Zafra Rodr√≠guez (ZAFRAR0926)

¬°Bienvenido al proyecto! Este repositorio demuestra c√≥mo construir un ambiente de desarrollo MLOps usando TFX, Docker y Jupyter Lab. Aqu√≠ se muestran todas las etapas:

Ingesta y selecci√≥n de caracter√≠sticas del dataset Forest Cover Type
Generaci√≥n de estad√≠sticas, inferencia y curado del esquema (con entornos TRAINING y SERVING)
Transformaci√≥n e ingenier√≠a de caracter√≠sticas mediante preprocesamiento personalizado
Registro y consulta de ML Metadata para rastrear la procedencia de los artefactos

**üì• 1. Descarga del Repositorio**

Para descargar el proyecto desde GitHub, ejecuta el siguiente comando en la terminal:

```bashgi
git clone https://github.com/zafrar0926/Proyecto1.git
```

***üì• 1.1. Navega al directorio clonado***

```bash
cd Proyecto_1
```

**üê≥ 2.Entorno de Ejecuci√≥n con Docker**

Este proyecto se ejecuta dentro de un contenedor Docker. Aseg√∫rate de tener Docker instalado en tu m√°quina o en la m√°quina virtual.

***2.1. Creaci√≥n de la Imagen Docker***

El Dockerfile se encuentra en la ra√≠z del proyecto y tiene el siguiente contenido:

***‚öôÔ∏è dockerfile***

FROM python:3.9
RUN mkdir /work
WORKDIR /work
COPY . .
RUN python -m pip install --upgrade pip
RUN pip install -r requirements.txt
RUN pip install apache-beam[interactive]==2.45.0
RUN pip install jupyter==1.0.0 -U && pip install jupyterlab==3.6.1
EXPOSE 8888
ENTRYPOINT ["jupyter", "lab", "--ip=0.0.0.0", "--allow-root"]

***‚öôÔ∏èDependencias***

El archivo requirements.txt contiene:

tfx==1.12.0
apache-beam==2.45.0
jsonschema==3.2.0
scikit-learn==1.6.1
Aseg√∫rate de que todas las dependencias se instalen correctamente durante la construcci√≥n de la imagen.

***2.2. Creaci√≥n de la Imagen Docker***

Para construir la imagen ejecuta:

```bash
docker build -t imagen_proyecto1 .
```

###  2.3. Levantar el Contenedor

Ejecuta el siguiente comando para levantar el contenedor:

**En Linux/Mac:**
```bash
docker run -d -p 8888:8888 -v $(pwd)/Desarrollo:/work --name contenedor_proyecto1 imagen_proyecto1
```

**En Windows (PowerShell):**

```
powershell
docker run -d -p 8888:8888 -v ${PWD}\Desarrollo:/work --name contenedor_proyecto1 imagen_proyecto1
```

**En Windows (CMD):**

```
cmd
docker run -d -p 8888:8888 -v %cd%\Desarrollo:/work --name contenedor_proyecto1 imagen_proyecto1
```

***Detalles***

-d: Modo "detached" (segundo plano)
-p 8888:8888: Mapea el puerto 8888 del contenedor al mismo puerto en tu m√°quina
-v "ruta_local":/work: Monta el directorio del proyecto en /work dentro del contenedor
--name contenedor_proyecto1: Asigna un nombre al contenedor

**Para acceder a Jupyter Lab, revisa los logs del contenedor para obtener el URL y token.** Por ejemplo:

```bash
docker logs contenedor_proyecto1
```

Abre el URL que aparezca (por ejemplo, http://<IP_MV>:8888/?token=...) en tu navegador.

### üìì 3. Ejecuci√≥n del Pipeline (Desarrollo.ipynb)

El notebook Desarrollo.ipynb contiene el pipeline completo, que incluye:

***3.1. Descarga y Preparaci√≥n del Dataset***

Descarga de datos:
Se descarga el dataset Forest Cover Type y se guarda en ./data/covertype/original.
Selecci√≥n de caracter√≠sticas:
Se eliminan columnas no deseadas y se realiza una selecci√≥n univariante usando SelectKBest.
El subconjunto resultante se guarda en
/work/notebooks/data/covertype/transformed/covertype_train_numeric_selected.csv.

***3.2. Prueba de Modelo Simple (Opcional)***

Se divide el dataset, se estandariza y se entrena un modelo Random Forest para obtener una m√©trica de precisi√≥n.

***3.3 Data Pipeline con TFX***

**Conexi√≥n a Metadata:**
Se configura una base de datos SQLite en /work/notebooks/ml_metadata.sqlite para almacenar artefactos.

**Ingesta con ExampleGen:**
Se convierte el CSV en TFRecords.

**Estad√≠sticas y Esquema:**
Se calculan estad√≠sticas con StatisticsGen y se infiere un esquema con SchemaGen.
Luego se "cura" el esquema (ajustando rangos y definiendo entornos TRAINING y SERVING).

**Validaci√≥n de Inferencia:**
Se simula un dataset de servicio (sin la columna Cover_Type) y se valida con ExampleValidator.

**Transformaci√≥n (Ingenier√≠a de Caracter√≠sticas):**
Se aplica una funci√≥n de preprocesamiento (definida en modules/preprocessing.py) mediante el componente Transform.

***3.4. Exploraci√≥n y Consulta de ML Metadata***

Se registran y consultan artefactos (Examples, ExampleStatistics, Schema, etc.) para rastrear la procedencia y validaci√≥n de los datos.

**üìãRequisitos del Taller**

Este proyecto cumple con todos los puntos especificados en el taller:

***Ingesta y transformaci√≥n de datos***

Con ExampleGen, StatisticsGen, SchemaGen, y Transform.

***Curado y validaci√≥n del esquema***

Se ajustan rangos (ej. Hillshade 9am: 0‚Äì255, Slope: 0‚Äì90) y se definen entornos TRAINING y SERVING.

***Ingenier√≠a de caracter√≠sticas***

Se aplica preprocesamiento consistente en entrenamiento e inferencia.

***Registro y seguimiento de metadatos***

Se exploran los artefactos y se rastrea la procedencia usando ML Metadata.

***Entorno reproducible***

Se utiliza Docker para crear un ambiente aislado y versionado.

***Versionamiento***

El c√≥digo est√° versionado en GitHub: [Proyecto1](https://github.com/zafrar0926/Proyecto1)

***üìù Notas Adicionales***

Configuraci√≥n de Rutas:
Revisa que las rutas dentro de los notebooks y scripts coincidan con la estructura del directorio en la MV.

Acceso a Jupyter Lab:
Consulta los logs del contenedor para obtener el URL y token de acceso.

Actualizaci√≥n del Esquema y ML Metadata:
Se muestran funciones para consultar y rastrear artefactos en la metadata, facilitando la auditor√≠a del pipeline.